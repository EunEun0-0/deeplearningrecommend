##  진행한 실험

### 1. 에폭(Epoch) 수 증가
- **변경 사항**: `5` -> `20`
- **비고**: 더 늘려보고 싶었지만, 학습에 너무 오랜 시간이 소요되어 20으로 제한했습니다.
- **결과**:

### 2. 학습률(Learning Rate) 증가
- **변경 사항**: `0.0001` -> `0.001`
- **사유**: 기존 학습 속도가 너무 느려 학습률을 높였습니다.
- **결과**:

### 3. `ReduceLROnPlateau` 콜백 추가
- **내용**: 검증 손실(validation loss)이 개선되지 않을 때 학습률을 동적으로 감소시키는 `reduce_lr` 콜백을 추가했습니다.
- **결과**:

---

##  회고

학습 시간이 예상보다 훨씬 길어져 계획했던 다양한 실험을 모두 진행하지 못한 점이 아쉽습니다. 특히 다른 모델 아키텍처를 테스트해보지 못한 것이 가장 아쉬움으로 남습니다.

결과적으로 미미하지만 성능 향상을 확인했으며, 더 효율적인 데이터 전처리 방법을 적용하여 모델을 다시 학습시켜보고 싶다는 생각이 들었습니다.
